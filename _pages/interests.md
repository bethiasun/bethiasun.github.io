---
layout: page
permalink: /interests/
title: interests
description:
nav: true
nav_order: 2
---

My research broadly centers on building cognitively-plausible deep learning models, seeking answers to questions like: 

- **The Paradox of Cognition**: As encapsulated by  <a href="https://home.csulb.edu/~cwallis/382/readings/482/smolensky.proper.treat.pdf">Smolensky's Paradox of Cognition</a>, there is an apparent need for both connectionist and symbolic systems to explain the full range of human cognition (<i>neural</i>: e.g., fluidity, statistical sensitivity, and perceptual grounding, <i> symbolic</i>: e.g., structured reasoning and compositionality). How can we reconcile these seemingly incompatible paradigms into one coherent, <i> unified </i> cognitive architecture that gives rise to the full scope of human cognitive capabilities? I believe the answer to this lies in the development of new mathematical formalisms that allow traditionally 'symbolic' capabilities to emerge naturally from completely continuous mathematics (i.e., a 'connectionist' framework all the way down, but one that <i> appears </i> symbolic when viewed at a higher level). To this end, my current work investigates the mathematical framework of the <a href="https://www.colorado.edu/ics/sites/default/files/attached-files/92-08.pdf">Integrated Connectionist Symbolic theory for cognition</a> (Smolensky, Legendre and Miyata).

- **How Humans Learn So Much From So Little**: The fundamental mystery of cognitive science contemplates how humans, even as infants, can acquire complex concepts, causal relationships, and intuitive theories about the physical and social world with such minimal input data. How is it possible that we learn all sorts of things given the statistically underconstrained nature of the learning problem? I am motivated to tackle this question from the <a href="https://www.jstor.org/stable/188064"> Child as Scientist</a> framework (Gopnik), which conceptualises human learning as active process of theory formation and theory revision. To this end, my current work investigates computational instantiations of this framework, specifically the Bayesian program induction work of Tenenbaum and colleagues.