---
layout: about
title: about
permalink: /
subtitle: #<a href='#'>Affiliations</a>. Address. Contacts. Motto. Etc.

profile:
  align: right
  image: prof_pic.jpg
  image_circular: false # crops the image to make it circular
  more_info: #>
    #<p>555 your office number</p>
    #<p>123 your address street</p>
    #<p>Your City, State 12345</p>

news: true # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page
---

Hi! I am a first year MPhil student at UNSW, advised by [Yang Song](https://cgi.cse.unsw.edu.au/~ysong/) and [Maurice Pagnucco](https://cgi.cse.unsw.edu.au/~morri/). Previously, I completed a dual B.S at the same institution in Mathematics and Computer Science.

I am broadly interested in building cognitively-plausible computational models of human intelligence, seeking answers to questions like: 

- **The Paradox of Cognition**: As encapsulated by  <a href="https://home.csulb.edu/~cwallis/382/readings/482/smolensky.proper.treat.pdf">Smolensky's Paradox of Cognition</a>, there is an apparent need for both connectionist and symbolic systems to explain the full range of human cognitive capabilities (<i>neural</i>: e.g., fluidity, statistical sensitivity, and perceptual grounding, <i> symbolic </i>: e.g., structured reasoning and compositionality). How can we reconcile these seemingly incompatible paradigms into one coherent, <i> unified </i> cognitive architecture that gives rise to the full scope of human cognition? 
  <p style="font-size:0.85em"> I believe the answer to this lies in the development of new mathematical formalisms that allow traditionally 'symbolic' capabilities to emerge naturally from completely continuous mathematics and optimisation (i.e., a 'connectionist' framework all the way down, but one equipped with the right mathematics such that it <i> appears </i> symbolic when viewed at a higher level). To this end, my current work investigates the mathematical framework of the <a href="https://www.colorado.edu/ics/sites/default/files/attached-files/92-08.pdf">Integrated Connectionist Symbolic theory for cognition</a> (Smolensky, Legendre and Miyata). </p>

- **How Humans Learn So Much From So Little**: The fundamental mystery of cognitive science contemplates how humans, even as infants, can acquire complex concepts, causal relationships, and intuitive theories about the physical and social world with such minimal input data. How is it possible that we learn all sorts of things - e.g., accurate generalisations, sophisticated mental models - given the statistically underconstrained nature of the learning problem? 
  <p style="font-size:0.85em"> I am inclined to tackle this question from Gopnik's framework of <a href="https://www.jstor.org/stable/188064"> Child as Scientist </a>, which likens human learning to an active process of theory building, where hypotheses are continually proposed to explain observed data, and subsequently tested, selected and refined. To this end, my current work investigates computational instantiations of this framework, specifically the Bayesian program induction work of Tenenbaum and colleagues. </p>

